{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c3c2fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 폰트 세팅 완료\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)\n",
    "\n",
    "print(\"한글 폰트 세팅 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93eeb95c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import gzip\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9c06ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "# float16 자료형으로 변경하여 메모리 공간 확보하기\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28ffe64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 188247\n",
      "Example:\n",
      ">> korean-english-park.train.en\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000000644 \u0000000765 \u0000000024 \u000000055552615 12360160402 016155\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ustar\u000000pj\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000staff\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000000000 \u0000000000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Much of personal computing is about \"can you top this?\"\n",
      ">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",
      ">> “Guard robots are used privately and professionally to detect intruders or fire,” Karlsson said.\n",
      ">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
      ">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 살펴보기\n",
    "file_dir = os.getcwd() + '/korean-english-park.train.tar.gz'\n",
    "\n",
    "with gzip.open(file_dir, 'rt') as f:\n",
    "    raw = f.read().splitlines()\n",
    "    \n",
    "print(\"Data Size:\", len(raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab9565e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['korean-english-park.train.en\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00000644 \\x00000765 \\x00000024 \\x0000055552615 12360160402 016155\\x00 0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00ustar\\x0000pj\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00staff\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00000000 \\x00000000 \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00Much of personal computing is about \"can you top this?\"', 'so a mention a few weeks ago about a rechargeable wireless optical mouse brought in another rechargeable, wireless mouse.', \"Like all optical mice, But it also doesn't need a desk.\"]\n",
      "['\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00korean-english-park.train.ko\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00000644 \\x00000765 \\x00000024 \\x0000064302104 12360160402 016146\\x00 0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00ustar\\x0000pj\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00staff\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00000000 \\x00000000 \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"', '모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하지 않는다.', '그러나 이것은 또한 책상도 필요로 하지 않는다.']\n"
     ]
    }
   ],
   "source": [
    "mid = len(raw) // 2 # 한국어와 영어 텍스트의 경계\n",
    "print(raw[:3])\n",
    "print(raw[mid: mid + 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8abf95c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딕셔너리 크기: 77591\n"
     ]
    }
   ],
   "source": [
    "# 리스트를 한국어 문장인 키와 영어 문장인 값으로 분리\n",
    "# 데이터의 형태: ['영어', '영어', ... '한국어', '한국어']\n",
    "\n",
    "keys =  raw[mid:]  # 뒤 쪽 절반인 한국어 부분  \n",
    "values = raw[:mid] # 앞 쪽 절반인 영어부분\n",
    "\n",
    "# zip() 함수와 dict() 함수를 사용하여 딕셔너리 생성\n",
    "dictionary = dict(zip(keys, values))\n",
    "\n",
    "print(\"딕셔너리 크기:\",len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95c8fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74832"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딕셔너리 내에 값의 중복을 제거하는 함수\n",
    "\n",
    "def remove_duplicate_values(original_dict):\n",
    "    # 값을 키로, 키를 값으로 하는 임시 딕셔너리 생성\n",
    "    temp_dict = {val: key for key, val in original_dict.items()}\n",
    "    # 다시 원래 형태로 변환하여 중복 제거된 딕셔너리 생성\n",
    "    result_dict = {val: key for key, val in temp_dict.items()}\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "unique_dict = remove_duplicate_values(dictionary)\n",
    "len(unique_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29fc393e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('약 200600밀리그램의, 비슷한 분량의 카페인은 또한 육체적 지구력을 강화시키는 데 효과적인 것 같으며, 특히 고도가 높은 곳에서 약해진 육체적 지구력을 일부 회복시켜주는 데 유용하다는 것이 이번 연구에서 밝혀졌다.', 'A similar dose of caffeine, about 200-600 mg, also appears effective in enhancing physical endurance and may be especially useful in returning some of the physical endurance lost at high altitude, the study found.')\n",
      "\n",
      "('의약 연구소는 정부에 과학 문제에 관해 자문하기 위해 의회가 설립 인가를 내어 준 민간 단체인 국립 과학 학회의 부속 단체이다.', 'The Institute of Medicine is part of the National Academy of Sciences, a private organization chartered by Congress to advise the government on scientific matters.')\n",
      "\n",
      "('아시아에서의 왕성한 수요 덕분에 일본의 수출이 9월에 연속 6개월간 증가하여, 무역 흑자가 1조550억엔(84억7,000만달러)으로 늘어났다고 재무성이 발표했다.', 'thanks to robust demand in Asia, boosting the trade surplus to 1.055 trillion yen ($8.47 billion), the Ministry of Finance said.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리 매핑 확인하기\n",
    "print(list(unique_dict.items())[10], end='\\n\\n')\n",
    "print(list(unique_dict.items())[11], end='\\n\\n')\n",
    "print(list(unique_dict.items())[12], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256d8a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74832"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus = list(unique_dict.items())\n",
    "len(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbf9ff5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 텍스트 길이: 74832\n",
      "영어 텍스트 길이: 74832\n",
      "\n",
      "중국이 604억달러의 비용이 소요되는 아마도 세계 에서 가장 값비싼 계획 중의 하나이며, 중국 역사상 가장 규모가 큰 수로 변경 계획을 밝혔다.\n",
      "China has unveiled plans for the largest water-diversion in its history and possibly one of the world's most expensive at $60.4 billion.\n",
      "\n",
      "이 사업은 중국에서 가장 긴 강인 양쯔강의 물을 강 유역이 말라 들어가고 있는 북부의 황허, 화이허, 그리고 하이허, 세 개의 강으로 돌리게 될 것이다.\n",
      "The project will channel water from the country's longest river, the Yangtze, to three rivers in the north, the Yellow, Huai and Hai, whose basins are running dry.\n",
      "\n",
      "이 야심찬 남북 수로 변경 사업은 더 습하고 홍수가 잦은 남부의 강 유역을 매우 건조한 북부 지방과 연결시키는 세 개의 수로를 따라 물을 이동시키게 될 것이다.\n",
      "The ambitious South-to-North Water Transfer Project will move water along three channels linking the wetter flood-prone southern basin to parched northern climes.\n",
      "\n",
      "최근의 사업 중에는 3개의 협곡 수력 발전 댐, 4,000킬로미터의 천연 가스 파이프라인 계획, 그리고 큉하이에서 티벳까지의 세계 최고도의 철로 건설이 포함되어 있다.\n",
      "This is just one of the latest of China's massive public works projects, recent ones including the Three Gorges hydroelectric dam, a proposed 4,000-kilometer natural-gas pipeline and the world's highest railroad from Qinghai to Tibet.\n",
      "\n",
      "수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      "Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
      "\n",
      "장쟈오 수자원부 차관은 사업 승인을 받기 위해 금년말까지 이 사업 계획이 의회에 제출될 것이라고 말했다.\n",
      "Vice Minister of the Water Resources ministry Zhang Jiyao said plans for the project would be submitted for approval to the cabinet by the end of the year.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 한국어와 영어 텍스트 분리하기\n",
    "kor_text = []\n",
    "eng_text = []\n",
    "\n",
    "for sentence in cleaned_corpus:\n",
    "    kor_text.append(sentence[0])\n",
    "    eng_text.append(sentence[1])\n",
    "    \n",
    "\n",
    "print(\"한국어 텍스트 길이:\", len(kor_text))\n",
    "print(\"영어 텍스트 길이:\", len(eng_text))    \n",
    "print()\n",
    "    \n",
    "# 분리된 내용 확인하기\n",
    "for k, e in zip(kor_text[55:61], eng_text[55:61]):\n",
    "    print(k)\n",
    "    print(e)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1159a",
   "metadata": {},
   "source": [
    "## 데이터 정제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f9df5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence, language='en', s_token=False, e_token=False):\n",
    "    # 앞뒤 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 영어의 경우 소문자로 변환\n",
    "    if language == 'en':\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "    # 구두점 주위에 공백 추가\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    \n",
    "    # 연속된 공백을 하나의 공백으로 대체\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # 언어에 따라 적절한 문자만 유지\n",
    "    if language == 'en':\n",
    "        # 영문자, 숫자, 특정 특수문자만 유지\n",
    "        sentence = re.sub(r\"[^a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "    elif language == 'ko':\n",
    "        # 한글, 숫자, 특정 특수문자만 유지\n",
    "        sentence = re.sub(r\"[^가-힣0-9?.!,]+\", \" \", sentence)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported language. Use 'en' for English or 'ko' for Korean.\")\n",
    "\n",
    "    # 앞뒤 공백 다시 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 시작 토큰 추가 (옵션)\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    # 종료 토큰 추가 (옵션)\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e4baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cd137ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 , 960만갤론 이상의 중유를 운반하던 손상된 유조선이 스페인 북서부 연안 130마일 해역에서 침몰하여 , 스페인 당국이 어업이 주요 산업인 이 지역에서 해안선 보호를 위해 황급히 서두르고 있다 .\n",
      "<start> carrying more than 19 . 6 million gallons of heavy fuel oil sank 130 miles off spain s northwest coast , leaving spanish authorities scrambling to protect the coastline in the region where fishing is the primary industry . <end>\n",
      "\n",
      "싣고 있는 기름이 모두 유출된다면 , 알라스카 프린스 윌리암 사운드에서 1989년에 발생했던 엑손 발데즈 기름 유출 사건의 규모보다 두 배 이상이 되는 사상 최대 규모의 기름 유출 사건 중의 하나가 될 것이라고 세계 야생 생물 기금이 경고하고 있다 .\n",
      "<start> the world wildlife fund warns that if all of the oil leaked , it would be one of the largest oil spills ever more than twice the size of the 1989 exxon valdez spill in alaska s prince william sound . <end>\n",
      "\n",
      "대도시를 완전히 파괴할 만큼 커다란 우주의 암석 덩어리들이 지구에 충돌하는 것은 이전에 생각했던 것보다 빈도가 훨씬 적은 , 대략 1천년에 한 번 정도이다 .\n",
      "<start> space boulders big enough to wipe out a major city slam into the earth about once every 1 , 000 years , much less frequently than previously thought . <end>\n",
      "\n",
      "핵폭발의 근거지를 찾아내는 국방성의 인공위성으로부터 얻은 수년간의 자료에 대한 전례 없는 조사에서 이러한 수정된 계산 결과가 나오게 되었다 .\n",
      "<start> the revised calculations come from an unprecedented examination of years of data that scour the ground for nuclear explosions . <end>\n",
      "\n",
      "최인원은 배드민턴 게임을 완벽하게 하고 싶어한다 .\n",
      "<start> choi in won wants to perfect his badminton game . <end>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "num_examples = 30000\n",
    "\n",
    "# 한국어 텍스트 전처리\n",
    "for text in kor_text[:num_examples]:\n",
    "    enc_corpus.append(preprocess_sentence(text, language='ko'))\n",
    "\n",
    "# 영어 텍스트 전처리\n",
    "for text in eng_text[:num_examples]:\n",
    "    dec_corpus.append(preprocess_sentence(text, language='en', s_token=True, e_token=True))    \n",
    "    \n",
    "\n",
    "# 전처리된 내용 확인하기\n",
    "for enc, dec in zip(enc_corpus[100:105], dec_corpus[100:105]):\n",
    "    print(enc)\n",
    "    print(dec)\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a6d67",
   "metadata": {},
   "source": [
    "## 데이터 전처리: 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abe92e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 20000\n",
    "oov_token = '<unk>'\n",
    "maxlen=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5be4d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', num_words=num_words, oov_token=oov_token)\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=maxlen)\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6ce82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "def kor_tokenize(corpus):\n",
    "    mecab = Mecab()\n",
    "    tokenized_corpus = [\" \".join(mecab.morphs(sentence)) for sentence in corpus]\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', num_words=num_words, oov_token=oov_token)\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=maxlen)\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c73e1bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tensors, enc_tokenizer = eng_tokenize(enc_corpus)\n",
    "dec_tensors, dec_tokenizer = kor_tokenize(dec_corpus)\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_tensors, dec_tensors, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3770b042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 40)\n",
      "(24000, 40)\n",
      "[[    1     1  5257  1194  3136   101 12424     1     1  2017     1   776\n",
      "      1 17681     1    60     2     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [ 5352  7373  5353     9   141    33   654     1     7     2     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [   27   850     1     1    26 12908     3  9244  5214   116  1000     1\n",
      "   9135     1  3403     1     1   343  6691     2     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  266 11728  4117 14243   495    37  9880     3  5401    37     1   919\n",
      "   3193  8468  3383     1   366     2     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [ 1098  1950  2093  2443   371  1950   375  9633  1923  1378 10548    20\n",
      "    264  1950    23   595 13691   628   375     1     8     2     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "\n",
      "[[    5   204  1124   782     4   723     4  3529 19276 19277 19278 19279\n",
      "  19280 19281   674 19282 19283   915 14565 14565   223     8  1229  5861\n",
      "     17    43    89    74   250    46   341     6     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    5   118     9  4685     9   330   374   257    43     9 10295  3010\n",
      "   9084  3414  1047    10   201 10295     3  3010  3414     4     6     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    5   143    77  9084  3530     3    32    20    60   894    70   438\n",
      "      9  6293     4     6     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    5  2182 19284  6294     7   475     2 19285   895    21    74   491\n",
      "    246 10296     3  1980     3  2567   163     2   312     4     6     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [   97    27  2455     9  5207     8  8135  7371    16  1398    10  1683\n",
      "    856    11    31  1379    14     9  3122  4102     8   296   867   591\n",
      "     52   387     8     2    85    12  5208   776    17  3531     7     9\n",
      "   1487   229     4     6]]\n"
     ]
    }
   ],
   "source": [
    "print(enc_train.shape)\n",
    "print(dec_train.shape)\n",
    "print(enc_train[:5])\n",
    "print()\n",
    "print(dec_tensors[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d3eb2d",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26345ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2341a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1d0e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f90c604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output: (64, 40, 512)\n",
      "Decoder Output: (64, 31433)\n",
      "Decoder Hidden State: (64, 512)\n",
      "Attention: (64, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "# 코드를 실행하세요.\n",
    "\n",
    "BATCH_SIZE     = 64\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
    "\n",
    "units         = 512  \n",
    "embedding_dim = 256\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "# sample input\n",
    "sequence_len = 40\n",
    "\n",
    "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "sample_output = encoder(sample_enc)\n",
    "\n",
    "print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_state, sample_output)\n",
    "\n",
    "print ('Decoder Output:', sample_logits.shape)\n",
    "print ('Decoder Hidden State:', h_dec.shape)\n",
    "print ('Attention:', attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e948b",
   "metadata": {},
   "source": [
    "## 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa4b8108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "111baa21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd16836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm    # tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c07bfbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/375 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_250/1845155999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n\u001b[0m\u001b[1;32m     12\u001b[0m                                 \u001b[0mdec_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                 \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmp91sa99gy.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(src, tgt, encoder, decoder, optimizer, dec_tok)\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dec_src'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_dec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m     \u001b[0m_py_for_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_for_stmt\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mprotected_body\u001b[0;34m(protected_iter)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0moriginal_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprotected_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0moriginal_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m       \u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmp91sa99gy.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0;32mnonlocal\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_src\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmphvehrucm.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, x, h_dec, enc_out)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    441\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0m\u001b[1;32m    444\u001b[0m           inputs, initial_state, training, mask, row_lengths)\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[1;32m    518\u001b[0m               **normal_gru_kwargs)\n\u001b[1;32m    519\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         last_output, outputs, new_h, runtime = gru_with_backend_selection(\n\u001b[0m\u001b[1;32m    521\u001b[0m             **normal_gru_kwargs)\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgru_with_backend_selection\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefun_standard_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0m_function_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_function_register\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdefun\u001b[0m \u001b[0mwrapped\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m   \"\"\"\n\u001b[0;32m-> 1781\u001b[0;31m   \u001b[0mconcrete_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gradient_functions_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3148\u001b[0m          \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m     \"\"\"\n\u001b[0;32m-> 3150\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   3151\u001b[0m         *args, **kwargs)\n\u001b[1;32m   3152\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3114\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m       \u001b[0;31m# TensorArrays and `None`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       func_outputs = nest.map_structure(convert, func_outputs,\n\u001b[0m\u001b[1;32m   1012\u001b[0m                                         expand_composites=True)\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    969\u001b[0m               (str(python_func), type(x)))\n\u001b[1;32m    970\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeps_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36mmark_as_return\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# of a new identity operation that the stateful operations definitely don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# depend on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_returned_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3943\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3944\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3945\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   3946\u001b[0m         \"Identity\", input=input, name=name)\n\u001b[1;32m   3947\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         compute_device)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3559\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3560\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3561\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3562\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack_for_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36mextract_stack_for_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    192\u001b[0m   \u001b[0mthread_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_thread_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m   return _tf_stack.extract_stack_for_node(\n\u001b[0;32m--> 194\u001b[0;31m       \u001b[0m_source_mapper_stacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthread_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m       _source_filter_stacks[thread_key][-1].internal_set, node)\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)    # tqdm\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "209e7bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 375/375 [01:40<00:00,  3.74it/s, Loss 4.3280]\n",
      "Test Epoch  1: 100%|██████████| 94/94 [00:32<00:00,  2.92it/s, Test Loss 4.2899]\n",
      "Epoch  2: 100%|██████████| 375/375 [01:13<00:00,  5.10it/s, Loss 4.2880]\n",
      "Test Epoch  2: 100%|██████████| 94/94 [00:07<00:00, 13.10it/s, Test Loss 4.3005]\n",
      "Epoch  3: 100%|██████████| 375/375 [01:14<00:00,  5.03it/s, Loss 4.2800]\n",
      "Test Epoch  3: 100%|██████████| 94/94 [00:07<00:00, 13.03it/s, Test Loss 4.3138]\n",
      "Epoch  4: 100%|██████████| 375/375 [01:14<00:00,  5.02it/s, Loss 4.2720]\n",
      "Test Epoch  4: 100%|██████████| 94/94 [00:07<00:00, 13.00it/s, Test Loss 4.3032]\n",
      "Epoch  5: 100%|██████████| 375/375 [01:14<00:00,  5.02it/s, Loss 4.2667]\n",
      "Test Epoch  5: 100%|██████████| 94/94 [00:07<00:00, 13.00it/s, Test Loss 4.3059]\n",
      "Epoch  6: 100%|██████████| 375/375 [01:14<00:00,  5.02it/s, Loss 4.2773]\n",
      "Test Epoch  6: 100%|██████████| 94/94 [00:07<00:00, 13.00it/s, Test Loss 4.2979]\n",
      "Epoch  7: 100%|██████████| 375/375 [01:14<00:00,  5.02it/s, Loss 4.2773]\n",
      "Test Epoch  7: 100%|██████████| 94/94 [00:07<00:00, 13.02it/s, Test Loss 4.3085]\n",
      "Epoch  8: 100%|██████████| 375/375 [01:14<00:00,  5.02it/s, Loss 4.2747]\n",
      "Test Epoch  8: 100%|██████████| 94/94 [00:07<00:00, 12.94it/s, Test Loss 4.2979]\n",
      "Epoch  9: 100%|██████████| 375/375 [01:14<00:00,  5.02it/s, Loss 4.2720]\n",
      "Test Epoch  9: 100%|██████████| 94/94 [00:07<00:00, 12.99it/s, Test Loss 4.3059]\n",
      "Epoch 10: 100%|██████████| 375/375 [01:14<00:00,  5.02it/s, Loss 4.2693]\n",
      "Test Epoch 10: 100%|██████████| 94/94 [00:07<00:00, 12.98it/s, Test Loss 4.3032]\n"
     ]
    }
   ],
   "source": [
    "# Define eval_step\n",
    "\n",
    "@tf.function\n",
    "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    enc_out = encoder(src)\n",
    "\n",
    "    h_dec = enc_out[:, -1]\n",
    "    \n",
    "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "    for t in range(1, tgt.shape[1]):\n",
    "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "        loss += loss_function(tgt[:, t], pred)\n",
    "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "# Training Process\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (test_batch, idx) in enumerate(t):\n",
    "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
    "                                    dec_val[idx:idx+BATCH_SIZE],\n",
    "                                    encoder,\n",
    "                                    decoder,\n",
    "                                    dec_tokenizer)\n",
    "    \n",
    "        test_loss += test_batch_loss\n",
    "\n",
    "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68b25edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_train.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f17c24e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: . .\n",
      "Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_250/2860932276.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_250/2860932276.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 572,
       "width": 70
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"안녕하세요. 만나서 반갑습니다.\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8958028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: .\n",
      "Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_250/2860932276.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_250/2860932276.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 572,
       "width": 56
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"이 야심찬 남북 수로 변경 사업은 더 습하고 홍수가 잦은 남부의 강 유역을 매우 건조한 북부 지방과 연결시키는 세 개의 수로를 따라 물을 이동시키게 될 것이다.\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621c4bc",
   "metadata": {},
   "source": [
    "## 정리 및 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba930ae",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "값을 바꾸어가면서 시도해본 것들\n",
    "- 자료형을 float16으로 바꾸기\n",
    "- 패딩의 maxlen을 50에서 40으로 바꾸기\n",
    "- 모델의 unit 크기 1025에서 512로 바꾸기\n",
    "- 배치 사이즈 16, 32, 64로 바꾸기\n",
    "\n",
    "문제점들\n",
    "- 모델이 원하는 결과를 출력하지 않는다. 모델이 the라는 토큰만 계속 반복하는 것을 확인할 수 있다.\n",
    "- 모델을 evaluate하는 과정에서 한글 input이 사라지고 특수문자인 .만 남는 것을 볼 수 있다. input 처리가 제대로 되지 않은 것을 확인할 수 있다.\n",
    "- 두 가지 가능성을 예상한다. evaluation 과정에서 한글 입력이 누락되었거나, 모델에서 한글 입력이 누락되었거나.\n",
    "\n",
    "예상 해결안\n",
    "- 한국어 텍스트와 영어 텍스트의 토큰화를 살펴보기\n",
    "- 인코더, 디코더, 바다나우 어텐션 코드 내부 분석하기\n",
    "- 개념 공부 더 하기..ㅠㅠ\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
